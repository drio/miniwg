What is a race condition in concurrent programming?|A race condition occurs when the <b>correctness</b> of a program depends on the <b>timing or ordering</b> of events (like thread execution), and different orderings can produce different results or data corruption
What is the difference between a race condition and non-deterministic output?|<b>Race condition</b>: Shared data accessed by multiple threads without proper synchronization, leading to data corruption or incorrect behavior<br><b>Non-deterministic output</b>: Different runs produce different results, but each result may be correct (e.g., goroutines printing in different orders)
Why are race conditions catastrophic in cryptography?|Because they can lead to critical security failures such as nonce reuse (which breaks encryption), key corruption, or using partially-written cryptographic state, all of which can leak secrets or allow attackers to decrypt/forge messages
What does Go's race detector do?|It instruments your code to detect when multiple goroutines access the same memory location concurrently where at least one access is a write, without proper synchronization. Run with <code>go test -race</code> or <code>go run -race</code>
What is the purpose of Go's init() function?|init() is a special function that runs automatically once when a package is loaded, before any other code (including main). It's used for package-level initialization that must happen exactly once
When is init() appropriate to use?|✅ Pure computation with no I/O or side effects<br>✅ Cannot fail (deterministic operations)<br>✅ Results are true constants (never change)<br>✅ Package-level initialization<br>❌ NOT for: side effects, complex initialization that can fail, state that varies between instances
Why does WireGuard use init() for InitialChainKey and InitialHash?|Because these are protocol constants computed from fixed strings. Computing them once at package load time (instead of on every handshake) is faster, thread-safe by default, and matches the Noise protocol specification
How does init() prevent race conditions?|Go guarantees init() runs exactly once, before any other code in the package, in a single goroutine, before main() starts. By the time any concurrent code runs, the initialization is already complete and visible to all goroutines
What would happen without init() if multiple goroutines tried to initialize the same variable?|Without proper synchronization (like sync.Once), multiple goroutines might: (1) all compute the value simultaneously, (2) one might read while another writes (partial data), (3) the value could be corrupted, (4) the program might crash
Show a race condition with a counter increment|<code>var counter int<br>// Two goroutines:<br>counter++ // Read-Modify-Write, NOT atomic</code><br><br>Both goroutines read counter=0, increment to 1, write 1. Final value: 1 (should be 2). Lost update!
Show the correct way to increment a counter atomically|<code>var counter atomic.Uint64<br>counter.Add(1) // Atomic operation, thread-safe</code><br><br>Or with a mutex:<br><code>var mu sync.Mutex<br>mu.Lock()<br>counter++<br>mu.Unlock()</code>
Why is nonce reuse in encryption a catastrophic race condition?|<code>var nonce uint64<br>func encrypt(data) {<br>  nonce++ // RACE!<br>}</code><br><br>Two threads might use the same nonce with the same key. In ChaCha20-Poly1305, nonce reuse leaks the keystream and allows attackers to decrypt messages or forge authenticated data
What is the correct pattern for nonce management in concurrent encryption?|<code>var nonce atomic.Uint64<br>func encrypt(data []byte) {<br>  n := nonce.Add(1) // Atomic increment<br>  // Use n for this encryption<br>}</code><br><br>This ensures each encryption gets a unique nonce even with concurrent access
What is sync.Once and when would you use it?|sync.Once ensures a function is executed exactly once, even if called from multiple goroutines concurrently. Use it for lazy initialization that must happen exactly once (e.g., initializing a singleton, opening a resource)
Show an example of sync.Once for initialization|<code>var (<br>  config Config<br>  once sync.Once<br>)<br><br>func getConfig() Config {<br>  once.Do(func() {<br>    config = loadConfig() // Runs exactly once<br>  })<br>  return config<br>}</code>
What is the double-checked locking pattern?|A pattern to reduce lock contention by checking a condition without a lock first, then acquiring the lock and checking again:<br><code>if !initialized { // Check 1: no lock<br>  mu.Lock()<br>  if !initialized { // Check 2: with lock<br>    initialize()<br>  }<br>  mu.Unlock()<br>}</code>
Why is double-checked locking needed in miniwg's initiateHandshake?|To prevent multiple goroutines from initiating handshakes simultaneously. First check (RLock) is cheap and handles the common case. Second check (Lock) ensures only one goroutine actually initiates when multiple arrive at the same time
What is the difference between sync.Mutex and sync.RWMutex?|<b>sync.Mutex</b>: Exclusive lock, only one goroutine can hold it<br><b>sync.RWMutex</b>: Readers-writer lock, multiple readers OR one writer. Use RLock() for reading (shared), Lock() for writing (exclusive)
When should you use RLock vs Lock on an RWMutex?|<b>RLock()</b>: When you only need to read shared state (allows concurrent readers)<br><b>Lock()</b>: When you need to modify shared state (exclusive access, blocks all readers and writers)
What happens if you defer a mutex unlock in a function that locks/unlocks multiple times?|The defer will only run when the function returns, NOT when you want it. This causes errors:<br><code>mu.Lock()<br>defer mu.Unlock() // Runs at function end!<br>mu.Unlock() // Double unlock - PANIC!<br>doWork()<br>mu.Lock() // Deadlock or panic</code>
When is it appropriate to use defer with mutex unlock?|When you lock exactly once and want it held until the function returns:<br><code>func process() {<br>  mu.Lock()<br>  defer mu.Unlock() // ✅ Good<br>  // All work here<br>  // Lock held until return<br>}</code>
Why should you unlock before expensive operations?|Holding a lock during expensive operations (crypto, I/O, network calls) blocks other goroutines unnecessarily, reducing concurrency and potentially causing deadlocks. Unlock, do expensive work, then relock if needed
What is a deadlock?|A situation where two or more goroutines are waiting for each other to release resources, causing all of them to block forever. Example: Thread A holds Lock1 and waits for Lock2, Thread B holds Lock2 and waits for Lock1
What is the correct order for acquiring multiple locks to avoid deadlock?|Always acquire locks in the <b>same order</b> across all goroutines. If you need Lock1 and Lock2, always acquire Lock1 first, then Lock2. Never acquire them in different orders in different parts of your code
What does go test -race detect that regular tests might miss?|Race conditions - concurrent access to shared memory without proper synchronization. Regular tests might pass because the race doesn't manifest with that particular timing, but -race instruments the code to detect all potential data races
Why might a program with race conditions work correctly most of the time?|Because race conditions depend on timing. If one goroutine usually finishes before another starts, the race might not manifest. But under different conditions (higher load, different hardware, different Go version), the race can cause failures
What is the memory model guarantee that init() provides?|Go's memory model guarantees that all init() functions complete before main() starts, and that variables initialized in init() are visible (with their final values) to all goroutines. This is a happens-before relationship
What is a happens-before relationship in concurrent programming?|A guarantee that one operation completes and its effects are visible before another operation begins. If A happens-before B, then B sees all changes made by A. Without this guarantee, compiler/CPU optimizations can reorder operations
Why are atomic operations necessary even on single variables?|Because modern CPUs and compilers can reorder operations and cache values. Without atomic operations, one goroutine might not see updates made by another, or might see partial updates (on 64-bit values on 32-bit systems)
What is the difference between atomic.LoadUint64 and reading a uint64 directly?|<b>atomic.LoadUint64(&amp;x)</b>: Guarantees you see the complete value, prevents compiler/CPU optimizations from reordering<br><b>x</b> (direct read): Might see stale cached value, might see partial value on 32-bit systems, no ordering guarantees
Show a data race with a boolean flag|<code>var ready bool<br>// Goroutine 1:<br>ready = true<br><br>// Goroutine 2:<br>if ready {<br>  // use data<br>}</code><br><br>Goroutine 2 might never see ready=true due to caching, or might see it out of order with other operations
How would you fix the boolean flag race condition?|<code>var ready atomic.Bool<br>// Goroutine 1:<br>ready.Store(true)<br><br>// Goroutine 2:<br>if ready.Load() {<br>  // use data<br>}</code><br><br>Or use a channel for signaling
What is a channel and how does it help with concurrency?|A channel is a typed conduit for communication between goroutines. It provides synchronization automatically - sending blocks until someone receives, receiving blocks until someone sends. This eliminates many race conditions
When should you use channels vs mutexes?|<b>Channels</b>: When communicating/passing data between goroutines, implementing pipelines, signaling events<br><b>Mutexes</b>: When protecting shared state accessed by multiple goroutines, especially for quick updates<br><br>Rule of thumb: "Share memory by communicating (channels), don't communicate by sharing memory (mutexes)"
What is a buffered channel and how does it differ from unbuffered?|<b>Unbuffered</b>: <code>ch := make(chan int)</code> - Send blocks until receive, synchronous<br><b>Buffered</b>: <code>ch := make(chan int, 10)</code> - Send blocks only when buffer full, allows asynchronous communication up to buffer size
What is a select statement used for in Go?|select allows a goroutine to wait on multiple channel operations simultaneously. It blocks until one case can proceed, or uses default for non-blocking. Example:<br><code>select {<br>case msg := &lt;-ch1:<br>case ch2 &lt;- val:<br>default:<br>}</code>
Why does miniwg use non-blocking sends with select?|<code>select {<br>case outbound &lt;- packet:<br>  // Queued successfully<br>default:<br>  // Queue full, drop packet<br>}</code><br><br>To prevent the reader goroutine from blocking if the main event loop is overwhelmed. This ensures the system stays responsive rather than deadlocking
What happens if you close a channel that's already closed?|<b>Panic!</b> Closing an already-closed channel causes a runtime panic. This is why you should only close channels from the sender side and have clear ownership of who can close
What happens if you send to a closed channel?|<b>Panic!</b> Sending to a closed channel causes a runtime panic. This is another reason to have clear ownership of channels and careful shutdown coordination
What does receiving from a closed channel return?|The zero value of the channel's type, and the second "ok" return value is false:<br><code>val, ok := &lt;-ch<br>if !ok {<br>  // Channel closed<br>}</code><br><br>Or in range: <code>for val := range ch</code> exits when channel closes
What is the purpose of the done channel pattern?|A way to signal goroutines to shut down:<br><code>done := make(chan struct{})<br>go func() {<br>  for {<br>    select {<br>    case &lt;-done:<br>      return<br>    // ... work ...<br>    }<br>  }<br>}()<br>close(done) // Signal shutdown</code>
Why use struct{} for signal-only channels instead of bool?|<code>struct{}</code> occupies zero bytes - it's the smallest type in Go. Since you're only signaling (not sending data), using struct{} is more explicit about intent and saves memory
What is a goroutine leak?|When a goroutine starts but never terminates (e.g., blocked on channel receive that never comes, infinite loop with no exit). Leaked goroutines waste memory and resources, and can accumulate over time
How can you detect goroutine leaks?|1. Use runtime.NumGoroutine() before and after operations in tests<br>2. Use tools like goleak package<br>3. Use pprof to analyze running goroutines: <code>go tool pprof http://localhost:6060/debug/pprof/goroutine</code>
What is the purpose of sync.WaitGroup?|To wait for a collection of goroutines to finish. Add(n) before starting goroutines, Done() when each finishes, Wait() blocks until all are done:<br><code>var wg sync.WaitGroup<br>wg.Add(2)<br>go func() { defer wg.Done(); work1() }()<br>go func() { defer wg.Done(); work2() }()<br>wg.Wait()</code>
Why should you call WaitGroup.Add() before starting the goroutine?|Because Add() must happen before Wait() is called. If you Add() inside the goroutine, there's a race where Wait() might be called before Add(), causing Wait() to return immediately (thinking there's no work)
What is the context package used for?|To carry deadlines, cancellation signals, and request-scoped values across API boundaries and goroutines. Allows graceful shutdown: parent context cancelled → all child contexts cancelled → all goroutines stop
Show a basic context cancellation pattern|<code>ctx, cancel := context.WithCancel(context.Background())<br>defer cancel()<br><br>go func() {<br>  for {<br>    select {<br>    case &lt;-ctx.Done():<br>      return<br>    // ... work ...<br>    }<br>  }<br>}()</code>
